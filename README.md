# Speaker Diarization ğŸ”Š

## Short description ğŸ–Šï¸

End-to-end speaker diarization pipeline answering **â€œwho spoke whenâ€** by combining pyannote (VAD, segmentation, embeddings), clustering (threshold / spectral), and Whisper for transcription. Produces time-stamped RTTM and a labeled transcript.

## Team (ï½ï¿£â–½ï¿£)ï½

* Ngo Xuan Kien â€” 23BI14239
* Tran Gia Khanh â€” 23BI14218
* Ngo Minh Phuoc â€” 23BI14361
* Nguyen The Khai â€” 23BI14205

## Key components (one line each) ğŸ—ï¸

* **Dataset:** VoxConverse (RTTM annotations).
* **Preprocessing:** mono 16 kHz conversion, basic denoising, segmentation.
* **Features:** neural speaker embeddings (pyannote) Â± MFCC/log-mel.
* **Clustering:** threshold-based or spectral clustering on embeddings.
* **ASR:** Whisper (tiny) for transcripts.
* **Evaluation:** DER, JER, confusion & overlap analysis.

## Outputs ğŸ¤–

* `*.rttm` â€” standard time-stamped speaker segments.
* `labeled_transcript.txt` â€” speaker-labeled transcript.
* Visualizations: PCA / t-SNE of embeddings, confusion/distance histograms.

## Evaluation ğŸ“

* Primary metric: **DER** (captures misses, false alarms, confusion).
* System handles overlap via VAD tuning and embedding-clustering design.
* Modular pipeline: VAD â†’ Embedding â†’ Clustering â†’ ASR â†’ Alignment (easy to swap modules).
 
## Important files ğŸ“ƒ

* `run_diarization.py` (or notebook) â€” pipeline entry point
* `requirements.txt` â€” dependencies (pinned)
* `reports/` â€” DER and embedding visualizations

## Contact ğŸ¤™

See Team section above. Submitted: **September 2025**.
